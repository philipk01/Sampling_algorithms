{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.linalg as la\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import scipy.stats as ss\n",
    "import math\n",
    "import random\n",
    "from collections import namedtuple\n",
    "%precision 4\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code optimization\n",
    "\n",
    "In order to optimize the code import *numba*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cholesky Update\n",
    "\n",
    "*Input*: the lower triangular Cholesky factor $L$ of the covariance matrix $\\pmb{\\Sigma} \\in \\mathbb{R}^{n \\times n}$,\n",
    "the vector $\\pmb{x} \\in \\mathbb{R}^{n}$, and their weights $w_1$ and $w_2$.\n",
    "\n",
    "*Output*: the lower triangular Cholesky factor $L^\\prime$ of $\\pmb{\\Sigma}^\\prime = w_1 \\pmb{\\Sigma} + w_2  \\pmb{x}^\\top \\pmb{x}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "def cholupdate(L, x, sign='+'):\n",
    "    d = len(x)\n",
    "    for i in range(d):\n",
    "        if sign == '+':\n",
    "            r = np.sqrt(L[i,i]**2 + x[i]**2)\n",
    "        elif sign == '-':\n",
    "            r = np.sqrt(L[i,i]**2 - x[i]**2)\n",
    "        c = r/L[i,i]\n",
    "        s = x[i]/L[i,i]\n",
    "        L[i,i] = r\n",
    "        if sign == '+':\n",
    "            L[i+1:d,i] = (L[i+1:d,i] + s*x[i+1:d]) / c\n",
    "        elif sign == '-':\n",
    "            L[i+1:d,i] = (L[i+1:d,i] - s*x[i+1:d]) / c\n",
    "        x[i+1:d] = c*x[i+1:d] - s*L[i+1:d,i]\n",
    "    return L"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "@numba.jit\n",
    "def rank_1_update_opt(L, u, alpha, beta):\n",
    "    #assert alpha > 0, 'Argument alpha should be positive'\n",
    "    #assert beta > 0, 'Argument beta should be positive'\n",
    "    v = np.copy(u)  #Added\n",
    "    d = len(u)\n",
    "    L = np.sqrt(alpha)*L  #Added\n",
    "    nL = np.zeros_like(L)\n",
    "    b = 1\n",
    "    for i in np.arange(d):\n",
    "        nL[i,i] = np.sqrt(L[i,i]**2 + (beta/b)*(v[i]**2))\n",
    "        gamma = b*L[i,i]**2 + beta*v[i]**2\n",
    "        v[i+1:d] = v[i+1:d] - (v[i]/L[i,i])*L[i+1:d,i]\n",
    "        nL[i+1:d,i] = (nL[i,i]/L[i,i])*L[i+1:d,i] + (nL[i,i]*beta*v[i]/gamma)*v[i+1:d]\n",
    "        b = b + beta*(v[i]**2/L[i,i]**2)\n",
    "    return nL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit(nopython=True) \n",
    "def rank_1_update(L, u, alpha, beta):\n",
    "    #assert alpha > 0, 'Argument alpha should be positive'\n",
    "    #assert beta > 0, 'Argument beta should be positive'\n",
    "    d = len(u)\n",
    "    L = np.sqrt(alpha)*L  #Added\n",
    "    b = 1\n",
    "    nL = np.zeros_like(L)\n",
    "    v = np.copy(u)  #Added\n",
    "    for j in np.arange(d):\n",
    "        nL[j,j] = np.sqrt(L[j,j]**2 + (beta/b)*(v[j]**2))\n",
    "        gamma = b*L[j,j]**2 + beta*v[j]**2\n",
    "        for k in range(j+1, d):\n",
    "            v[k] = v[k] - (v[j]/L[j,j])*L[k,j]\n",
    "            nL[k,j] = (nL[j,j]/L[j,j])*L[k,j] + (nL[j,j]*beta*v[j]/gamma)*v[k]\n",
    "        b = b + beta*(v[j]**2/L[j,j]**2)\n",
    "    return nL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test rank 1 update"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_Gaussian(d):\n",
    "    mean = np.random.random(size=d)\n",
    "    X = np.random.random(size=(10*d, d))\n",
    "    cov = X.T@X\n",
    "    return mean, cov\n",
    "\n",
    "def samples_random_Gaussian(d, N):\n",
    "    m, C = random_Gaussian(d=d)\n",
    "    samples = ss.multivariate_normal.rvs(mean=m, cov=C, size=N)\n",
    "    return samples, m, C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_rank_1_update(d, alpha, beta):\n",
    "    # Create a random covariance matrix, i.e. C is symmetric and positive definite.\n",
    "    m, C = random_Gaussian(d)\n",
    "    L = la.cholesky(C)\n",
    "    \n",
    "    # Create a random vector\n",
    "    v = np.random.random(size=d)\n",
    "    \n",
    "    # Update the covariance matrix\n",
    "    uC = alpha*C + beta*np.outer(v,v)\n",
    "    \n",
    "    # Calculate its Cholesky factor\n",
    "    uL = la.cholesky(uC)\n",
    "    \n",
    "    # Update the Cholesky factor of the initial covariance\n",
    "    nL = rank_1_update(L=L, u=v, alpha=alpha, beta=beta)\n",
    "    \n",
    "    # The two return statements should be equivalent.\n",
    "    return np.allclose(uC, nL@nL.T) and np.allclose(uL, nL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_rank_1_update(d=100, alpha=100, beta=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rank_1_update(dimensions, alphas, betas, nbtrials=10):\n",
    "    for d in dimensions:\n",
    "        for alpha in alphas:\n",
    "            for beta in betas:\n",
    "                for n in range(nbtrials):\n",
    "                    if not check_rank_1_update(d=d, alpha=alpha, beta=beta):\n",
    "                        print('d: ', d, 'n: ', n)\n",
    "    else: \n",
    "        print('Pass')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "base = np.array([2, 10, 100, 1000, 10000, 100000, 1000000, 1000000, 10000000])\n",
    "Alphas = np.array([(n-1)/n for n in base])\n",
    "Betas =  np.array([n/(n+1) for n in base])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pass\n"
     ]
    }
   ],
   "source": [
    "test_rank_1_update(dimensions=[200], \n",
    "                   alphas=Alphas,\n",
    "                   betas=Betas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Incrementally update the first two moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_moments(mean, M2, sample, n):\n",
    "    w = 1/(n+1)\n",
    "    new_mean = mean + w*(sample - mean)\n",
    "    delta_bf, delta_af = sample - mean, sample - new_mean\n",
    "    new_M2 = M2 + np.outer(delta_bf, delta_af)\n",
    "    return new_mean, new_M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_moments(samples):\n",
    "    N, d = samples.shape\n",
    "    mean, M2 = np.zeros(d), np.zeros(shape=(d, d))\n",
    "    for n in range(N):\n",
    "        z_sample = samples[n]\n",
    "        mean, M2 = update_moments(mean=mean, M2=M2, sample=z_sample, n=n)\n",
    "    return mean, M2/(N-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test incrementally update\n",
    "\n",
    "The algorithms above have been tested up to dimension $d=200$ of the statespace and $N= 1,000,000$ samples\n",
    "and each time they gave the same result, i.e. np.allclose returned True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_moments(d, N):\n",
    "    z_samples = ss.multivariate_normal.rvs(mean=np.zeros(d), cov=np.eye(d,d), size=N)\n",
    "    moments_mean, moments_cov = calculate_moments(z_samples)\n",
    "    emp_mean, emp_cov = np.mean(z_samples, axis=0), np.cov(z_samples, rowvar=False)\n",
    "    return np.allclose(moments_mean, emp_mean) and np.allclose(moments_cov, emp_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_moments(d=200, N=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare incremental update of $C$ and $L$\n",
    "\n",
    "In case of the Cholesky update we \n",
    "- First, calculate the empirical covariance $C$ of the first $2 d$ generated samples\n",
    "- Next, we calculate its Cholesky factor $L$\n",
    "- From then on, $L$ is updated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def update_mean(samples):\n",
    "    N, d = samples.shape\n",
    "    initial_period = 2*d\n",
    "    initial_cov = np.cov(samples[:initial_period], rowvar=False)\n",
    "    initial_mean = np.mean(samples[:initial_period], axis=0)\n",
    "    mean = initial_mean\n",
    "    for n in range(initial_period, len(samples)):\n",
    "        sample = samples[n]\n",
    "        w = 1/(n+1)\n",
    "        mean = (1-w)*mean + w*sample\n",
    "    return mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "@numba.jit\n",
    "def update_L(samples):\n",
    "    N, d = samples.shape\n",
    "    initial_period = 2*d\n",
    "    initial_cov = np.cov(samples[:initial_period], rowvar=False)\n",
    "    initial_mean = np.mean(samples[:initial_period], axis=0)\n",
    "    C = initial_cov\n",
    "    L = la.cholesky(initial_cov) \n",
    "    mean = initial_mean\n",
    "    for n in range(initial_period, len(samples)):\n",
    "        sample = samples[n]\n",
    "        w = 1/(n+1)\n",
    "        L = rank_1_update(L, sample-mean, alpha=(n-1)/n, beta=w)\n",
    "        mean = (1-w)*mean + w*sample\n",
    "    return L@L.T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Time to Test\n",
    "\n",
    "BM has succesfully done the test up to dimension 200 and 1 million samples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_Cholesky_update(d, N):\n",
    "    # Generate samples of a Gaussian with random mean and covariance\n",
    "    samples, mean, cov = samples_random_Gaussian(d=d, N=N)\n",
    "    \n",
    "    # Use numpy functions to calculate the sample mean and variance\n",
    "    sample_mean, sample_cov = np.mean(samples, axis=0), np.cov(samples, rowvar=False)\n",
    "    \n",
    "    # Use the update functions 'updated_mean' and 'updated_cov' to calculate again the sample mean and variance\n",
    "    updated_mean, updated_cov = update_mean(samples=samples), update_L(samples=samples)\n",
    "    \n",
    "    # Check whether they give the same results\n",
    "    return np.allclose(sample_mean, updated_mean) and np.allclose(sample_cov, updated_cov)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_Cholesky_update(d=100, N=1000)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
